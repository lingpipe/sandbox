\chapter{Suffix Arrays}\label{chap:suffix-arrays}

Suffix arrays provide a convenient data structure for finding all of
the repeated substrings of arbitrary length in texts.  They also have
applications to indexing.  They are used for applications ranging
from plagiarism detection to language modeling to indexing for phrase
searches.

LingPipe provides suffix arrays that operate at either the character
level or the token level.  At the token level, there is a further
class that manages collections of documents.  Applications include
plagiarism detection, language modeling, indexing

\section{What is a Suffix Array?}

A simple example will suffice to illustrate the basic workings of
suffix arrays.  Suppose we have the string \stringmention{abracadabra},
presented here with the positions in the sequence numbered.
%
\begin{verbatim}
      abracadabra
      012345678901
      0         1
\end{verbatim}
%

A suffix array represents the suffixes of a string.  For instance, the
example string \stringmention{abracadabra} has the following suffixes, given
with their starting position in the string.
%
\begin{center}
\begin{tabular}{rl}
\tblhead{Pos} & \tblhead{Suffix}
\\ \hline
0 & \stringmention{abracadabra} \\
1 & \stringmention{bracadabra} \\
2 & \stringmention{racadabra} \\
3 & \stringmention{acadabra} \\
\end{tabular}
%
\hspace*{0.5in}
%
\begin{tabular}{rl}
\tblhead{Pos} & \tblhead{Suffix}
\\ \hline
4 & \stringmention{cadabra} \\
5 & \stringmention{adabra} \\
6 & \stringmention{dabra} \\
7 & \stringmention{abra} \\
\end{tabular}
%
\hspace*{0.5in}
%
\begin{tabular}{rl}
\tblhead{Pos} & \tblhead{Suffix}
\\ \hline
8 & \stringmention{bra} \\
9 & \stringmention{ra} \\
10 & \stringmention{a} \\
{} & {}
\end{tabular}
\end{center}
%

A suffix array is nothing more than the set of suffixes
sorted.  The suffixes are represented by their starting
positions.  For our running example, we have the following
sorted list of suffixes.

%
\begin{center}
\begin{tabular}{rrl}
\tblhead{Idx} & \tblhead{Pos} & \tblhead{Suffix}
\\ \hline
0 & 10 & \stringmention{a} \\
1 & 7 & \stringmention{abra} \\
2 & 0 & \stringmention{abracadabra} \\
3 & 3 & \stringmention{acadabra} \\
4 & 5 & \stringmention{adabra} \\
5 & 8 & \stringmention{bra} \\
\end{tabular}
%
\hspace*{0.5in}
%
\begin{tabular}{rrl}
\tblhead{Idx} & \tblhead{Pos} & \tblhead{Suffix}
\\ \hline
6 & 1 & \stringmention{bracadabra} \\
7 & 4 & \stringmention{cadabra} \\
8 & 6 & \stringmention{dabra} \\
9 & 9 & \stringmention{ra} \\
10 & 2 & \stringmention{racadabra} \\
{} & {}
\end{tabular}
\end{center}
%

The suffix array itself is just the array of first-character
positions for the suffixes.  In our example, the suffix array is
the following array of \code{int} values.
%
\begin{verbatim}
{ 10, 7, 0, 3, 5, 8, 1, 4, 6, 9 , 2 }
\end{verbatim}
%
Note that the suffix itself may be retrieved given the underlying
string and the position of the first character.

The utility of a suffix array is that it brings together suffixes that
share common prefixes.  For instance, it is easy to see that there are
two suffixes that start with the sequence \stringmention{bra}, one
starting at position 8 and one starting at position 1.  We can also see
that there are five substrings starting with \stringmention{a} and
two starting with \stringmention{abra}.  

Every substring of our original string is representable as a prefix
of a suffix.  For instance, the substring \stringmention{ca} spanning
from position 7 (inclusive) to 9 (exclusive) is the two-character
prefix of the suffix \stringmention{cadabra} starting at position 7.

Thus we can easily find all the matching substrings in a string.  For
instance, if we want to find all the instances of strings of length
three or more that occur two or more times in the text, we just scan
down the suffix array, where we will find \stringmention{abr} and
\stringmention{bra} both occur twice.  

LingPipe provides a class for creating suffix arrays of characters
from texts, suffix arrays of tokens from texts and a tokenizer
factory, and suffix arrays of tokens from a collection of named
documents and a tokenizer.


\section{Character Suffix Arrays}

LingPipe implements suffix arrays where the symbols are characters in
the class \code{CharSuffixArray} in the package
\code{com.aliasi.suffixarray}.  We cover token suffix arrays in the
next section).

\subsection{Demo Code Walkthrough}

We have provided a demo in class \code{CharSuffixArrayDemo} in this
chapter's package.  The demo class does little more than build a
suffix array and then walk over it extracting the suffixes in order.
The relevant code, after assigning the input argument to a string
\code{text} is
%
\codeblock{CharSuffixArrayDemo.1}
%
The code uses the constructor without a specification on the maximum
length.  Then it walks through all of the positions, up to the length
of the suffix array.  From each, it extracts the position in the
underlying string and the suffix running from that position to the end
of the string.  We have elided the print statements, as usual.

The second part of the demo extracts all of the repeated substrings.
As such, it starts with a loop over the length of matching substrings,
then extracts them inside.
%
\codeblock{CharSuffixArrayDemo.2}
%
We start from the maximum possible match, which is one less
than the length of the string, and repeat for all lengths above 1.
Within the loop, we call the \code{prefixMatches()} method on the
suffix array with the specified length.  This returns a list of
spans represented as integer arrays.  If the size is zero, there
are no repeated substrings of the specified length, and we continue
to the next iteration of the loop.  

If there are matches, we iterate over the arrays of positions.
For each such position, we extract the start and end position,
assigning them to local variables for readability.  Finally, we
loop over the matching positions from first (inclusive) to last
(exclusive), and for each match, pull out the position, then generate
the string corresponding to the match.  We do not show the print
routines for these values, but show examples in the next section.


\subsection{Running the Demo}

We've provided an Ant target \code{char-demo} to run the demo.  
The property \code{text} specifies the text for which to build
a suffix array.  Using our running example, we have
%
\commandlinefollow{ant -Dtext=abracadabra char-demo}
\begin{verbatim}
abracadabra
012345678901
0         1

Idx  Pos  Suffix           Idx  Pos  Suffix
  0   10  a                  6    1  bracadabra
  1    7  abra               7    4  cadabra
  2    0  abracadabra        8    6  dabra
  3    3  acadabra           9    9  ra
  4    5  adabra            10    2  racadabra
  5    8  bra
\end{verbatim}
%
As before, the index is the (implicit) index into the
suffix array, the position indicates the position in the
original string, and the suffix is the range of characters
from the position to the end of the original string.

After writing out the basic suffix array, the demo carries on with
writing out the positiosn of all repeated substrings of length greater
than one.
%
\begin{verbatim}
start=  7 len=  4  abra       start=  7 len=  2  ab
start=  0 len=  4  abra       start=  0 len=  2  ab

start=  7 len=  3  abr        start=  8 len=  2  br
start=  0 len=  3  abr        start=  1 len=  2  br

start=  8 len=  3  bra        start=  9 len=  2  ra
start=  1 len=  3  bra        start=  2 len=  2  ra
\end{verbatim}
%
For instance, this indicates that the substring \stringmention{abra}
appeared twice, once starting at position 7 and once starting at
position 0.  

Although there are only pairs of matches here, the number can
quickly grow with repetitive strings.  The worst case situation for
overlaps is with a sequence of the same character. 
%
\commandlinefollow{ant -Dtext=yyyyy char-demo}
\begin{verbatim}
yyyyy
012345

Idx   Pos  Suffix      Idx   Pos  Suffix
  0     4  y             3     1  yyyy
  1     3  yy            4     0  yyyyy
  2     2  yyy


start=  1 len=  4  yyyy       start=  3 len=  2  yy
start=  0 len=  4  yyyy       start=  2 len=  2  yy
                              start=  1 len=  2  yy
start=  2 len=  3  yyy        start=  0 len=  2  yy
start=  1 len=  3  yyy
start=  0 len=  3  yyy
\end{verbatim}
%
In this example, the suffixes are merely sorted by length, and
there are two matches of length four, three of length three, and
four of length two.


\section{Token Suffix Arrays}

LingPipe's class \code{TokenSuffixArray}, in package
\code{suffixarray}, supports token-based suffix arrays.  Token suffix
arrays work exactly the same way as character suffix arrays, only at
the granularity of tokens.

\subsection{Advantages of Token Arrays}

There are three main advantages to using token-based suffix arrays.
First, they are more efficient at representing texts and finding
long substrings, as the suffix array itself will not be as large.  The
saving depends on the average token length.  With the overhead of
the tokenization object and the tokens themselves, a token suffix
array may wind up being larger in memory than a character suffix array.
But it should be faster to construct and faster to find long matches.

The second gain is in understandability of matches.  Usually in
language-processing applications, we only care about matches including
all or none of a token.  Substring matching involving partial tokens
is rarely useful at an application level.

The third gain is in the ability to relax the comparison criteria.
For instance, tokenizers can case normalize, stop list, dispose of
whitespace and punctuation, and so on.  This allows greater control
over the matching.

\subsection{Token-Based Array Demo}

The class \code{TokenSuffixArrayDemo} in this chapter's package,
\code{suffixarray}, illustrates the basic usage pattern
for token suffix arrays.  

\subsubsection{Code Walk Through}

The command-line input is set to the \code{String} variable
\code{text}, and then a suffix array based on tokens is constructed as
follows.
%
\codeblock{TokenSuffixArrayDemo.1}
%
We first access the singleton tokenizer factory for Indo-European
languages, then wrap it in a lower-case filter that downcases all of
the text in the tokens (see \refchap{tokenization} for more on tokenizers
and tokenizer factories).  We then construct the tokenization itself
using the text and the tokenizer factory.  The \code{Tokenization}
encapsulates the raw text, the list of tokens extracted, and each
token's start and end position in the raw text.  This allows us to map
the tokens back to their positions in the underlying text (see
\refsec{tokenization-tokenization-class} for details of the
\code{Tokenization} class).  Finally, we construct the token suffix
array itself using just the tokenization, which defaults to unbounded
suffix lengths and the default document separator (we cover document
separators in \refsec{suffix-arrays-doc-sa}).

We see the tokenization in action in the next section of the code,
which accesses the tokenization from the suffix array and prints out
its tokens and their positions.
%
\codeblock{TokenSuffixArrayDemo.2}

Next, we iterate through the suffixes themselves.
%
\codeblock{TokenSuffixArrayDemo.3}
%
Here we consider all positions up to the length of the suffix
array, pulling out the value of the suffix array, which is
an index into the tokens in the tokenization.  

The final section of the demo finds subsequences of tokens
of a specified length that match in the text.  
%
\codeblock{TokenSuffixArrayDemo.4}
%
As with the character suffix array, we consider different lengths and
for each length, find all the matches using the \code{prefixMatches()}
method on token suffix arrays.  Each match is an array of integers
recording the start (inclusive) and end (exlcusive) position in the
suffix array.  Note that these positions are contiguous in the suffix
array because the suffix array is sorted; this is why we can just loop
incrementing the variable \code{j}.  Finally, given a position in the
suffix array, we find the position in the text and the corresponding
suffix.  As with our other demos, we've elided the print statements.


\subsubsection{Running the Demo}

The Ant target \code{token-demo} runs the demo, with property
\code{text} providing the text input.

\commandlinefollow{ant -Dtext="John ran HOME and Mary ran home." token-demo}
\begin{verbatim}
TEXT:
John ran HOME and Mary ran home.
012345678901234567890123456789012
0         1         2         3

TOKENS
  0 (  0,  4) john        4 ( 18, 22) mary
  1 (  5,  8) ran         5 ( 23, 26) ran
  2 (  9, 13) home        6 ( 27, 31) home
  3 ( 14, 17) and         7 ( 31, 32) .
\end{verbatim}
%
The first part of the output just reports the tokens
and their start (inclusive) and end (exclusive) positions 
in the text.  

After this, we see the suffix array itself, with the
index into the basic list of tokens and the suffix itself.
%
\begin{verbatim}
SUFFIX ARRAY (idx,array,suffix)
    0   7 .
    1   3 and Mary ran home.
    2   6 home.
    3   2 HOME and Mary ran home.
    4   0 John ran HOME and Mary ran home.
    5   4 Mary ran home.
    6   5 ran home.
    7   1 ran HOME and Mary ran home.
\end{verbatim}
%
Note that the sorting is on the tokens, not the suffixes,
so that \stringmention{HOME}, \stringmention{John}, and
\stringmention{Mary} sort as if they were lower case.  Finally,
we see the matching substrings, this time at a token level.
%
\begin{verbatim}
MATCHING SUBSTRINGS
  len   sa  txt  suffix           len   sa  txt  suffix
    2    6    5  ran home           1    6    5  ran
    2    7    1  ran HOME           1    7    1  ran

    1    2    6  home
    1    3    2  HOME
\end{verbatim}
%
Note that the comparison is also done by token, so taht
\stringmention{ran home} and \stringmention{ran HOME} are considered a
match.  This time, we've also printed the length 1 matches.


\section{Document Collections as Suffix Arrays}%
\label{section:suffix-arrays-doc-sa}

The third class implemented in LingPipe's \code{suffixarray} package
is for managing collections of documents in a suffix array.  This
class is based on an underlying token suffix array whose text is
derived by concatenating all the documents together with a distinguished
separator.  This process is all handled internally in the document
suffix array.

\subsection{Demo}

The document suffix array demo is in the file \code{DocSuffixArrayDemo}
in this chapter's package.  The demo will walk over a directory recursively
and add the text of every plain file to the document collection.  It
will then index these documents in a suffix array so as to support
searching for shared substrings.

\subsubsection{Code Walkthrough}

A document suffix array is constructed from a mapping from
string-based document identifiers to text strings.  We start
with a path assigned to file variable \code{dir} and an integer
match length \code{len}.  We create a map to hold the
identifier-to-document mapping and then call the static helper
method \code{addFiles()} to create it from the directory.
%
\codeblock{DocSuffixArrayDemo.1}
%
The \code{addFiles()} function is defined recursively in the
obvious way, using the path to the file as the file identifier
and the character content of the file as its text.
%
\codeblock{DocSuffixArrayDemo.2}
%
The result is that we have a map from document identifier strings
to the text of the document.

Next, we create a tokenizer factory that lowercases tokens extracted
by the Indo-European tokenizer and filters out any non-word
tokens (where words are defined as containing only ASCII alpha-numeric
characters).
%
\codeblock{DocSuffixArrayDemo.3}

With the document mapping and tokenizer factory, we are ready to
build a document suffix array.
%
\codeblock{DocSuffixArrayDemo.4}
%
First, we set a boundary token of \stringmention{eeooff}.  Note that this
boundary token must tokenize to itself in the tokenizer, or the
constructor will throw an exception.  We also set a maximum suffix
length to be the maximum possible length.

Once we've constructed the document suffix array, we pull out the
underlying token suffix array using the method \code{suffixArray()},
then find and print the matches.
%
\codeblock{DocSuffixArrayDemo.5}
%
The same method, \code{prefixMatches(int)}, is used to pull out
the matches.  The primary utility of the document suffix array is
to manage the document identifiers and map matches back to them,
as seen in the following code that loops over the matches. 

As with the token-based suffix arrays, we get a contiguous range
of indexes into the suffix array, here assigned to integer value
\code{j}.  We then pull the text that was matched out just as evore,
using the \code{substring()} method on token suffix arrays.  We also
find the position of the token in the underlying text using the
method \code{suffixArray()}, which returns the value of the suffix
array for its argument.  We then use this position to pull out
the identifier for the document using the document suffix array
method \code{textPositionToDocId()}.  As usual, we have elided
the print statements and boilerplate.


\subsubsection{Running the Demo}

First, we need to gather data.  We have used the test section of the
20 newsgroups corpus for that purpose; see
\refsec{corpora-20-newsgroups} for download instructions and a
description of the corpus.  The documents are newsgroup postings, so
they contain a large degree of overlapping text because of the heavy
use of quoting previous messages.  We assume the data have been
unpacked into the directory \code{data/20news/20news-bydate-test}, which
we have placed in the top-level for the book.

The Ant target \code{doc-demo} runs the demo, using the properties
\code{len} for the required match length and \code{dir} for a path
to the directory containing the documents.
%
\commandlinefollow{ant -Dlen=100 -Ddir=../../data/20news/20news-bydate-test doc-demo}
\begin{verbatim}
Extracting files from path=C:\lpb\data\20news\20news-bydate-test
Match length=100
# of docs=7532
# of tokens=2298193
\end{verbatim}
%
There are roughly 7500 documents and 2.3 million tokens, and it takes
a little less than 30 seconds and 2GB of memory to build the array on
my aging workstation using 64-bit Java 1.6.

It then starts dumping out matches, which are prohibitively long, so
we truncate their tails here for readability:
%
\begin{verbatim}
rec.sport.hockey\53942  0 0 0.00 0 0 0 0 1.000 WAS Byron Dafoe ...
rec.sport.hockey\54274  0 0 0.00 0 0 0 0 1.000 WAS Byron Dafoe ...
...
\end{verbatim}
%
These are the first two results, which are reports of player
statistics in two different posts on the \code{rec.sport.hockey}
newsgroup.  The text printed out is the text spanned by the matching
tokens in the original document.  Given the various access methods, it'd
also be possible to retrieve the tokens that actually matched.


\section{Implementation Details} 

Suffix arrays are represented internally very directly as an array of
\code{int} values.  During construction, an array of \code{Integer}
positions is created and sorted using a \code{Comparator} for
suffixes.  This boxing of \code{int} values as \code{Integer}
positions requires an object per position in the suffix array and also
an \code{int} at the point the array is being written out, both of
which are relatively costly.
%
\footnote{In the future, we may replace this crude implementation with
  a more efficient version that is able to sort the \code{int} values
  in a suffix array directly.}

Thus the overall construction time is no worse than $\bigO{n \log n}$
comparisons, where $n$ is the length of the string.  The current
implementation uses a very naive comparator that may require up to
$\bigO{n}$ operations to compare suffixes where \code{n} is the number
of matching characters in the prefixes of the suffixes.  Texts
with long repeated substrings, like our earlier example
\stringmention{yyyyyy}, present worst-case scenarios.%
%
\footnote{A more efficient comparator implementation would dynamically
track the number of matching prefix characters in its divide-and-conquer
step --- merge sort is particularly easy to understand in this way.  We
would then start all comparisons after the matching characters in the
subsegment of data being sorted.}












