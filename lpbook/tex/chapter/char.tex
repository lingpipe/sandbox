\chapter{Characters and Strings}\label{chap:char}

\firstchar{F}ollowing Java, LingPipe uses Unicode character
representations.  In this chapter, we describe the Unicode character
set, discuss character encodings, and how strings and other character
sequences are created and used in Java.


\section{Character Encodings}

For processing natural language text, we are primarily concerned with
the representation of characters in natural languages.  A set of
(abstract) characters is known as a character set.  These range from
the relatively limited set of 26 characters (52 if you count upper and
lower case characters) used in English to the tens of thousands of
characters used in Chinese.


\subsection{What is a Character?}

Precise definitions of characters in human writing systems is a
notoriously tricky business.  

\subsubsection{Types of Character Sets}

Characters are used in language to represent sounds at the level of
phonemic segments \eg{Latin}, syllables \eg{Japanese Hirigana and
Katakana scripts, Linear B, and Cherokee}, or words or morphemes, also
known as logograms \eg{Chinese Han characters, Egyptian
hieroglyphics}.  

These distinctions are blurry.  For instance, both Chinese characters
and Egyptian hieroglyphs are typically pronounced as single syllables
and words may require multiple characters.

\subsubsection{Abstraction over Visualization}

One problem with dealing with characters is the issue of visual
representation versus the abstraction.  Character sets abstract away
from the visual representations of characters.  

A sequence of characters is also an abstract concept.  When
visualizing a sequence of characters, different writing systems lay
them out differently on the page.  When visualizing a sequence of
characters, we must make a choice in how to lay them out on a page.
English, for instance, traditionally lays out a sequence of characters
in left to right order horizontally across a page. 
Arabic, on the other hand, lays out a sequence of
characters on a page horizontally from right to left.  In contast,
Japanese was traditionally set from top to bottom with the following
character being under the preceding characters.

English stacks lines of text from top to bottom, whereas traditional
Japanese orders its columns of text from right to left.  

When combining multiple pages, English has pages that ``turn'' from
right to left, whereas Arabic and traditional Japanese conventionally
order their pages in the opposite direction.  Obviously, page order
isn't relevant for digital documents rendered a page at a time, such
as on e-book readers.

Even with conventional layouts, it is not uncommon to see caligraphic
writing or signage laid out in different directions.  It's not
uncommon to see English written from top to bottom or diagonally from
upper left to lower right.


\subsubsection{Compound versus Primitive Characters}

Characters may be simple or compound.  For instance, the character
'\"o' used in German is composed of a plain Latin 'o' character with
an umlaut diacritic on top.  Diacritics are visual representations
added to other characters, and there is a broad range of them in
European languages.  

Hebrew and Arabic are typically written without vowels.  In very
formal writing, vowels may be indicated in these languages with
diacritics on the consonants.  Devanagari, a script used to write
languages including Hindi and Nepali, includes pitch accent marks.

The Hangul script used for Korean is a compound phonemic system often
involving multiple glyphs overlaid to form syllabic units.


\subsection{Coded Sets and Encoding Schemes}

Eventually, we need to represent sequences of characters as sequences
of bytes.  There are two components to a full character encoding.

The first step is to define a coded character set, which assigns each
character in the set a unique non-negative integer code point.  For
instance, the English character 'A' (capital A) might be assigned the
code point 65 and 'B' to code point 66, and so on.  Code points are
conventionally written using hexadecimal notation, so we would
typically use the hexadecmial notation 0x41 instead of the decimal
notation 65 for capital A.

The second step is to define a character encoding scheme that maps
each code point to a sequence of bytes (bytes are often called octets
in this context).

Translating a sequence of characters in the character set to a
sequence of bytes thus consists of first translating to the sequence
of code points, then encoding these code points into a sequence of
bytes.


\subsection{Legacy Character Encodings}

We consider in this section some widely used character encodings, but
because there are literally hundreds of them in use, we can't be
exhaustive.  

The characters in these and many other character sets are part of
Unicode.  Because LingPipe and Java both work with Unicode, typically
the only thing you need to know about a character encoding in order
to convert data in that encoding to Unicode is the name of the
character encoding.

\subsubsection{ASCII}

ASCII is a character encoding consisting of a small character set of
128 code points.  Being designed by computer scientists, the numbering
starts at 0, so the code points are in the range 0--127 (inclusive).
Each code point is then encoded as the corresponding single unsigned
byte with the same value.  It includes characters for the standard
keys of an American typewriter, and also some ``characters''
representing abstract typesetting notions such as line feeds and
carriage returns as well as terminal controls like ringing the
``bell''.

The term ``ASCII'' is sometimes used informally to refer to character
data in general, rather than the specific ASCII character encoding.

\subsubsection{Latin1 and the Other Latins}

Given that ASCII only uses 7 bits and bytes are 8 bits, the natural
extension is to add another 128 characters to ASCII.  Latin1
(officially named ISO-8859-1) did just this, adding common accented
European characters to ASCII, as well as punctuation like upside down
exclaimation points and question marks, French quote symbols, section
symbols, a copyright symbol, and so on.  

There are 256 code points in Latin1, and the encoding just uses the
corresponding unsigned byte to encode each of the 256 characters
numbered 0--255.

The Latin1 character set includes the entire ASCII character set.
Conveniently, Latin1 uses the same code points as ASCII for the ASCII
characters (code points 0--127).  This means that every ASCII encoding
is also a Latin1 encoding of exactly the same characters.

Latin1 also introduced ambiguity in coding, containing both an 'a'
character, the '\"{}' umlaut character, and their combination '\"{a}'.
It also includes all of 'a', 'e', and the compound '\ae', as well as
'1', '/', '2' and the compound $\frac{1}{2}$.

With only 256 characters, Latin1 couldn't render all of the characters
in use in Indo-European languages, so a slew of similar standards,
such as Latin2 (ISO-8859-2) for (some) Eastern European languages,
Latin3 (ISO-8859-1) for Turkish, Maltese and Esperanto, up through
Latin16 (ISO-8859-16) for other Eastern European languages, new styles
of Western European languages and Irish Gaelic.  

\subsubsection{Windows 1252}

Microsoft Windows, insisting on doing things its own way, uses a
character set known as Windows-1252, which is almost identical to Latin1,
but uses code points 128--159 as graphical characters, such as curly
quotes, the euro and yen symbols, and so on.

\subsubsection{Big5 and GB(K)}

The Big5 character encoding is used for traditional Chinese scripts
and the GB (more recently GBK) for simplified Chinese script.  Because
there are so many characters in Chinese, both were designed to use a
fixed-width two-byte encoding of each character.  Using two bytes
allows up to $2^{16} = 65,536$ characters, which is enough for most
of the commonly used Chinese characters.

\subsection{Unicode}

Unicode is the de facto standard for character sets of all kinds.  The
latest version is Unicode 5.2, and it contains over 1,000,000 distinct
characters drawn from hundreds of languages (technically, it assumes
all code points are in the range 0x0 to 0x10FFFF (0 to 1,114,111 in
decimal notation).

One reason Unicode has been so widely adopted is that it contains
almost all of the characters in almost all of the widely used
character sets in the world.  It also happens to have done so in a
thoughful and well-defined manner.

Conveniently, Unicode's first 256 code points (0--255) exactly match
those of Latin1, and hence Unicode's first 128 code points (0--127)
exactly match those of ASCII.

Unicode code points are conventionally displayed in text using a
hexadecimal representation of their code point padded to at least four
digits with initial zeroes, prefixed by \code{U+}.  For instance, code
point 65 (hex 0x41), which represents capital A in ASCII, Latin1 and
Unicode, is conventionally written \unicode{0041} for Unicode.

The problem with having over a million characters is that it would
require three bytes to store each character ($2^{24} = 16,777,216$).
This is very wasteful for encoding languages based on Latin characters
like Spanish or English.

\subsubsection{Unicode Transformation Formats}

There are three standard encodings for Unicode code points that are
specified in the Unicode standard, UTF-8, UTF-16, and UTF-32 (``UTF''
stands for ``Unicode transformation format'').%
%
\footnote{There are also non-standard encodings of (subsets of) 
Unicode, like Apache Lucene's and the one in Java's
\code{DataOutput.writeUTF()} method.}
%
The numbers represent the coding size; UTF-8 uses single bytes,
UTF-16 pairs of bytes, and UTF-32 quadruples of bytes.

\subsubsection{UTF-32}

The UTF-32 encoding is fixed-width, meaning each character occupies
the same number of bytes (in this case, 4).  As with ASCII and
Latin1, the code points are encoded directly as bits in base 2.

There are actually two UTF-32 encodings, UTF-32BE and UTF-32LE,
depending on the order of the four bytes making up the 32 bit blocks.
In the big-endian (BE) scheme, bytes are ordered from left to right
from most significant to least significant digits (like for bits in a
byte).  

In the little-endian (LE) scheme, they are ordered in the
opposite direction.  For instance, in UTF-32BE, \unicode{0041}
(capital A), is encoded as 0x00000041, indicating the four byte
sequence 0x00, 0x00, 0x00, 0x41.  In UTF32-LE, it's encoded as
0x41000000, corresponding to the byte sequence 0x41, 0x00, 0x00, 0x00.

There is also an unmarked encoding scheme, UTF-32, which tries to
infer which order the bytes come in.  Due to restrictions on the
coding scheme, this is usually possible.  In the simplest case,
0x41000000 is only legal in little endian, because it'd be out of
range in big-endian notation.  

Different computer processors use different endian-ness
internally.  For example, Intel and AMD x86 architecture is little
endian, Motorola's PowerPC is big endian.  Some hardware, such
as Sun Sparc, Intel Itanium and the ARM, is called bi-endian, because
endianness may be switched.

\subsubsection{UTF-16}

The UTF-16 encoding is variable length, meaning that different code
points use different numbers of bytes.  For UTF-16, each character is
represented using either two bytes (16 bits) or four bytes (32 bits).

Because there are two bytes involved, their order must be defined.  As
with UTF-32, UTF-16BE is the big-endian order and UTF-16LE the
little-endian order.

In UTF-16, code points below \unicode{10000} are represented using a
single byte in the natural base-2 encodings.  For instance, our old
friend \unicode{0041} (capital A) is represented in big endian as
the sequence of bytes 0x00, 0x41.  

Code points at or above \unicode{10000} are represented using four
bytes arranged in two pairs.  Calculating the two pairs of bytes
involves bit-twiddling.  For instance, given a code point
\code{codepoint}, the following code
calculates the four bytes.
%
\footnote{This code example and the following one for decoding were
adapted from the example code supplied by the Unicode Consortium in
their FAQ at 
\urldisplay{http://unicode.org/faq/utf\_bom.html}
}
%
\begin{verbatim}
static final int LEAD_OFFSET = 0xD800 - (0x10000 >> 10);
static final int SURROGATE_OFFSET = 0x10000 - (0xD800 << 10) - 0xDC00;

int lead = LEAD_OFFSET + (codepoint >> 10);
int trail = 0xDC00 + (codepoint & 0x3FF);

int byte1 = lead >>> 8;
int byte2 = lead & 0xFF;
int byte3 = trail >>> 8;
int byte4 = trail & 0xFF;
\end{verbatim}
%
Going the other way around, given the four bytes, we
can calculate the code point with the following code.
%
\begin{verbatim}
int lead = byte1 << 8 | byte2;
int trail = byte3 << 8 | byte4;

int codepoint = (lead << 10) + trail + SURROGATE_OFFSET;
\end{verbatim}

Another way to view this transformation is through the following
table.%
%
\footnote{Adapted from {\it Unicode Standard Version 5.2}, Table 3-5.}
%
\begin{center}
\begin{tabular}{|r|r|}
\hline
\tblhead{Code Point Bits} & \tblhead{UTF-16 Bytes} 
\\ \hline
\code{xxxxxxxx xxxxxxxx} & \code{xxxxxxxx xxxxxxxx}
\\ \hline
\code{000uuuuuxxxxxxxxxxxxxxxx} & \code{110110ww wwxxxxxx 110111xx xxxxxxxx}
\\ \hline
\end{tabular}
\end{center}
%
Here \code{wwww} = \code{uuuuu} - 1 (interpreted as numbers then
recoded as bits).  The first line indicates is that if the value fits
in 16 bits, those 16 bits are used as is.  Note that this
representation is only possible because not all code points between 0
and $2^{16}-1$ are legal.  The second line indicates that if we have a
code point above \unicode{10000}, we strip off the high-order five
bits uuuuu and subtract one from it to get four bits wwww; again, this
is only possible because of the size restriction on uuuuu.  Then,
distribute these bits in order across the four bytes shown on the
right.  The constants 110110 and 110111 are used to indicate what are
known as surrogate pairs.

Any 16-bit sequence starting with 110110 is the leading half of a
surrogate pair, and any sequence starting with 110111 is the trailing
half of a surrogate pair.  Any other sequence of initial bits means a
16-bit encoding of the code point.  Thus it is possible to determine
by looking at a pair of bytes whether we have a whole character, the
first half of a character represented as a surrogate pair, or the
second half of a character represented as a pair.

\subsubsection{UTF-8}

UTF-8 works in much the same way as UTF-16 (see the previous section),
only using single bytes as the minimum code size.  We
use the table-based visualization of the encoding scheme.%
%
\footnote{Adapted from {\it Unicode Standard Version 5.2},  Table 3-6.}
%
\begin{center}
\begin{tabular}{|r|r|}
\hline
\tblhead{Code Point Bits} & \tblhead{UTF-8 Bytes}
\\ \hline
\code{0xxxxxxxx} & \code{0xxxxxxx}
\\ \hline
\code{00000yyyyyxxxxxx} & \code{110yyyyy 10xxxxxx}
\\ \hline
\code{zzzzyyyyyyxxxxxx} & \code{1110zzzz 10yyyyyy 10xxxxxx}
\\ \hline
\code{000uuuuuzzzzyyyyyyxxxxxx} & \code{11110uuu 10uuzzzz 10yyyyyy 10xxxxxx}
\\ \hline
\end{tabular}
\end{center}
%
Thus 7-bit ASCII values, which have values from \unicode{0000} to
\unicode{007F}, are encoded directly in a single byte.  Values from
\unicode{0080} to \unicode{07FF} are represented with two bytes, 
values between \unicode{0800} and \unicode{FFFF} with three bytes, 
and values between \unicode{10000} and \unicode{10FFFF} with four bytes.


\subsubsection{Non-Overlap Principle}

The UTF-8 and UTF-16 encoding schemes obey what the Unicode Consortium
calls the ``non-overlap principle.''  Technically, the leading,
continuing and trailing code units (bytes in UTF-8, pairs of bytes in
UTF-16) overlap.  Take UTF-8 for example.  Bytes starting with
\code{0} are singletons, encoding a single character in the range 
\unicode{0000} to \unicode{007F}.  Bytes starting with \code{110}
are the leading byte in a two-byte sequence representing a character
in the range \unicode{0080} to \unicode{07FF}.  Similarly, bytes
starting with \code{1110} represent the leading byte in a three-byte
sequence, and \code{11110} the leading byte in a four-byte sequence.
Any bytes starting with \code{10} are continuation bytes.

What this means in practice is that it is possible to reconstruct
characters locally, without going back to the beginning of a file.
At most, if a byte starts with \code{10} you have to look back
up to three bytes to find the first byte in the sequence.

Furthermore, the corruption of a byte is localized so that the rest of
the stream doesn't get corrupted if one byte is corrupted.

Another advantage is that the sequence of bytes encoding one character
is never a subsequence of the bytes making up another character.  This
makes applications like search more robust.


\subsubsection{Byte Order Marks}

In the encoding schemes which are not explicitly marked as being
little or big endian, namely UTF-32, UTF-16 and UTF-8, it is also
legal, according to the Unicode standard, to prefix the sequence of
bytes with a byte-order mark (BOM).  It is not legal to have
byte-order marks preceding the explicitly marked encodings, UTF-32BE,
UTF-32LE, UTF-16BE, UTF-16LE.

For UTF-32, the byte-order mark is a sequence of four bytes indicating
whether the following encoding is little endian or big endian.  the
sequence 0x00, 0x00, 0xFE, 0xFF indicates a big-endian encoding and
the reverse, 0xFF, 0xFE, 0x00, 0x00 indicates little endian.

For UTF-16, two bytes are used, 0xFE, 0xFF for big endian, and the
reverse, 0xFF, 0xFE for little endian.

Although superfluous in UTF-8, the three byte sequence 0xEF, 0xBB,
0xBF is a ``byte order mark'', though there is no byte order to mark.  
As a result, all three UTF schemes may be distinguished by inspecting
their initial bytes.

Any text processor dealing with Unicode needs to handle the byte order
marks.  Some text editing packages automatically insert byte-order
marks for UTF encodings and some don't.

\subsubsection{Character Types and Categories}

The Unicode specification defines a number of character types and
general categories of character.  These are useful in Java
applications because characters may be examined programatically for
their class membership and the classes may be used in regular
expressions.

For example, category ``Me'' is the general category for enclosing
marks, and ``Pf'' the general category for final quote punctuation,
whereas ``Pd'' is the general category for dash-like punctuation, and
``Sc'' the category of currency symbols.  Unicode supplies a notion of
case, with the category ``Lu'' used for uppercase characters and
``Ll'' for lowercase.

Unicode marks the directionality in which characters are typically
wirtten using character types like ``R'' for right-to-left
and ``L'' for left-to-right.

\subsubsection{Canonical Forms}

Consider again the problem of compound characters.  For example,
consider the three characters: \unicode{00E0},
\unicodedesc{latin small letter a with grave}, rendered
\charmention{\`a}, \unicode{0061}, \unicodedesc{latin small letter a}, 
rendered as \charmention{a}, and \unicode{0300},
\unicodedesc{combining grave accent}, which is typically rendered
by combining it as an accent over the previous character.  For most
purposes, the combination \unicode{00E0} means the same thing in text
as \unicode{0061} followed by \unicode{0300}.

In order to aid text processing efforts, such as search, Unicode
defines a notion of canonical decomposition.  The \techdefs{canonical
decomposition}{unicode!canonical decomposition} of \unicode{00E0} is
as the sequence \unicode{0061},
\unicode{0300}.  In general, a full canonical decomposition continues
to decompose characters into their components until a sequence of
non-decomposible characters is produced.  Furthermore, if there is
more than one nonspacing mark (like \unicode{0300}), then they are
sorted into a canonical order.

From the notion of canonical decomposition, two seqeunces are said to
be \techdefs{canonical equivalents}{unicode!canonical equivalent} if their
full canonical decompositions are equal.


\section{Encoding Java Programs}

Java has native support for many encodings, as well as the ability to
plug in additional encodings as the need arises (see
\refsec{supported-encodings}).  Java programs themselves may be
written in any supported character encoding.

If you use characters other than ASCII characters in your Java
programs, you should provide the \code{javac} command with a
specification of which character set you used.  If it's not specified,
the platform default is used, which is typically Windows-1252 on
Windows systems and Latin1 on other systems, but can be modified as
part of the install.  

The command line to write your programs in Chinese using Big5 encoding
is
%
\begin{verbatim}
javac -encoding Big5 ...
\end{verbatim}
%
For Ant, you want to use the \code{encoding} attribute on the
\code{javac} task, as in
%
\begin{verbatim}
<javac encoding="Big5" ...
\end{verbatim}


\subsection{Unicode Characters in Java Programs}

Even if a Java program is encoded in a small character set encoding
like ASCII, it has the ability to express arbitrary Unicode characters
by using escapes.  In a Java program, the sequence
\code{{\bk}u}\codeVar{xxxx}  behaves like the character
\unicode{\codeVar{xxxx}}, where \codeVar{xxxx} is a hexadecimal
encoded value padded to four characters with leading zeroes.

For instance, instead of writing

\begin{verbatim}
int n = 1;
\end{verbatim}
%
we could write
%
\begin{verbatim}
\u0069\u006E\u0074\u0020\u006E\u0020\u003D\u0020\u0031\u003B
\end{verbatim}
%
and it would behave exactly the same way, because
\charmention{i} is \unicode{0069}, \charmention{n} is
\unicode{006E}, \charmention{t} is \unicode{0074},
the space character is \unicode{0020}, and so on, up
through\charmention{;}, which is \unicode{003B}.

As popular as Unicode is, it's not widely enough supported in
components like text editors and not widely enough understood among
engineers.  Writing your programs in any character encoding other than
ASCII is thus highly error prone.  Our recommendation, which we follow
in LingPipe, is to write your Java programs in ASCII, using the full
\code{{\bk}u}\codeVar{xxxx} form of non-ASCII characters.


\section{\code{char} Primitive Type}

Java's primitive \code{char} data type is essentially a 16-bit (two
byte) unsigned integer. Thus a \code{char} can hold values between 0
and $2^16-1 = 65535$.  Furthermore, arithmetic over \code{char} types
works like an unsigned 16-bit representation, including casting a
\code{char} to a numerical primitive type \ie{\code{byte}, \code{short}, 
\code{int}, or \code{long}}.

\subsubsection{Character Literals}\label{section:character-literals}

In typical uses, instances of \code{char} will be used to model text
characters.  For this reason, there is a special syntax for character
literals.  Any character wrapped in single quotes is treated as
a character in a program.  For instance, we can assign a character
to a variable with 
%
\begin{verbatim}
char c = 'a'; 
\end{verbatim}
%
Given the availability of arbitrary Unicode characters in Java
programs using the syntax \code{{\bk}u}\codeVar{xxxx}, it's easy
to assign arbitrary Unicode characters.  For instance, 
to assign the variable \code{c} to the character \charmention{\`a},
\unicode{00E0}, use
%
\begin{verbatim}
char c = '\u00E0'; 
\end{verbatim}
%
Equivalently, because values of type \code{char} act like unsigned
short integers, it's possible to directly assign integer values
to them, as in
%
\begin{verbatim}
char c = 0x00E0;
\end{verbatim}
%
The expression \code{{\bk}0x00E0} is an integer literal in hexadecimal
notation.  In general, the compiler will infer which kind of integer
is intended.  

Because the Java \code{char} data type is only 16 bits, the Unicode
escape notation only goes up to \unicode{FFFF}.

Several characters may not be used directly within character (or
string) literals: new lines, returns, form feeds, backslash, or a
single quote character.  We can't just drop in a Unicode escape
like \code{{\bk}u000A} for a newline, because that behaves just
like a newline itself.  To get around this problem, Java provides
some special escape sequences which may be used in character and
string literals.  
%
\begin{center}
\hfill
\begin{tabular}{lll}
\tblhead{Escape} & \tblhead{Code Point} & \tblhead{Description}
\\
\code{{\bk}n} & \unicode{000A} & \unicodedesc{newline}
\\
\code{{\bk}t} & \unicode{0009} & \unicodedesc{tab}
\\
\code{{\bk}b} & \unicode{0008} & \unicodedesc{backspace}
\\
\code{{\bk}r} & \unicode{000D} & \unicodedesc{return}
\end{tabular}
\hfill
\begin{tabular}{lll}
\tblhead{Escape} & \tblhead{Code Point} & \tblhead{Description}
\\
\code{{\bk}f} & \unicode{000C} & \unicodedesc{form feed}
\\
\code{{\bk}{\bk}} & \unicode{005C} & \unicodedesc{backslash}
\\
\code{{\bk}'} & \unicode{0027} & \unicodedesc{single quote}
\\
\code{{\bk}"} & \unicode{0022} & \unicodedesc{double quote}
\end{tabular}
\hfill
\end{center}
%
For instance, we'd write
%
\begin{verbatim}
char c = '\n';
\end{verbatim}
%
to assign the newline character to the variable \code{c}.

\subsubsection{Character Arithmetic}

A character expression may be assigned to an integer result, as in
%
\begin{verbatim}
int n = 'a';
\end{verbatim}
%
After this statement is executed, the value of the variable \code{n}
will be 97.  This is often helpful for debugging, because it allows
the code points for characters to be printed or otherwise examined.

It's also possible, though not recommended, to do arithmetic with Java
character types.  For instance, the expression \code{'a'+1} is equal
to the expression \code{'b'}.

Character data types behave differently in the context of string
concatenation than integers.  The expressions \code{'a' + "bc"} and
\code{{\bk}u0061 + "bc"} are identical because the compiler treats
\code{{\bk}u0061} and \code{'a'} identically, because the Unicode
code point for \charmention{a} is \unicode{0061}.  Both expressions
evaluate to a string equal to \code{"abc"}.  

The expression \code{0x0061 + "bc"} evaluates to \code{"97bc"},
because \code{0x0061} is taken as a hexadecimal integer literal, which
when concatenated to a string, first gets converted to its
string-based decimal representation, \code{"97"}.  There are static methods in
\code{java.lang.Integer} to convert integers to string-based
representations.  The method \code{Integer.toString(int)} may be used
to convert an integer to a string-based decimal notation;
\code{Integer.toHexString(int)} does the same for hex.

\subsubsection{Characters Interpreted as UTF-16}

Java made the questionable decision to use 2-byte representations for
characters.  This is both too wide and too narrow.  It's wasteful for
representing text in Western European languages, where most characters
have single-byte representations.  It's also too narrow, in that
any code point above \unicode{FFFF} requires two characters to
represent in Java; to represent code points would require an
integer (primitive \code{int} type, which is 4 bytes).
%
\footnote{The designers' choice is more understandable given that there were no
code points that used more than a single pair of bytes for UTF-16 when
Java was designed, though Unicode all along advertised that it would
continue to add characters and was not imposing a 16-bit upper limit.}

When \code{char} primitives are used in strings, they are interpreted
as UTF-16.  For any code point that uses only two bytes in UTF-16,
this is just the unsigned integer representation of that code point.
This is why UTF-16 seemed so natural for representing characters in
the original Java language design.  Unfortunately, for code points
requiring four bytes in UTF-16, Java requires two characters, so now
we have all the waste of 2-bytes per character and all the
disadvantages of having Unicode code points that require multiple
characters.


\section{\code{Character} Class}

Just like for the numerical types, there is a class,
\code{Character}, used to box an underlying primitive
of type \code{char} with an immutable reference.  As for numbers, the
preferred way to acquire an instance of \code{Character} is with the
static factory method \code{Character.valueOf(char)}.  Autoboxing and
unboxing works the same way as for numerical values.  

Like the numerical classes, the \code{Character} class is also
serializable and comparable, with comparison being carried out based
on interpreting the underlying \code{char} as an unsigned integer.
There are also utilities in Java to sort sequences of \code{char}
values (such as strings) in a locale-specific way, because not every
or dialect of a language uses the same lexicographic sorting.

Equality and hash codes are also defined similarly, so that two
character objects are equal if and only if they reference the same
underlying character.

\subsection{Static Utilities}

The \code{Character} class supports a wide range of Unicode-sensitive
static utility constants and methods in addition to the factory method
\code{valueOf()}.

For each of the Unicode categories, there is a constant, represented
using a byte, because the class predates enums.  For instance, the
general category ``Pe'' in the Unicode specification is represented by
the constant \code{END\_PUNCTUATION} and the general category of
mathematical symbols, ``Sm'' in Unicode, is represented by the
constant\code{MATH\_SYMBOL}.

For many of these constants, there are corresponding methods.  For
instance, the method \code{getDirectionality(char)} returns the
directionality of a character as a byte value, which can then be tested
against the possible values represented as static constants.  There
are also useful methods for determining the category of a characer,
such as \code{isLetter(char)} and \code{isWhitespace(char)}.

Because multiple Java \code{char} instances might be needed to
represent a code point, there are also methods operating on code
points directly using integer (primitive \code{int}) arguments.  For
instance, \code{isLetter(int)} is the same as \code{isLetter(char)}
but generalized to arbitrary code points.  The method
\code{charCount(int)} returns the number of \code{char} values
required to represent the code point (so the value will be 1 or 2,
reflecting 2 or 4 bytes in UTF-16).  The methods
\code{isLowSurrogate(char)} and \code{isHighSurrogate(char)} determine
if the \code{char} represents the first or second half of the UTF-16
representation of a code point above \unicode{FFFF}.  

The method \code{charPointAt(char[],int)} determines the code point
that starts at the specified index int he array of \code{char}.  The
method \code{charPointCount(char[],int,int)} returns the number of
code points encoded by the specified \code{char} array slice.


\section{\code{CharSequence} Class}

Java provides an interface for dealing with sequences of characters
aptly named \code{CharSequence}.  It resides in the package
\code{java.lang}, so it's automatically imported.  Implementations
include strings and string builders, which we describe in the next
sections.

The character sequence interface specifies a method \code{length()}
that returns the number of characters in the sequence.  

The method \code{charAt(int)} may be used to return the character at a
specified position in the string.  Like arrays, positions are numbered
starting from zero.  Thus the method must be passed an integer in the
range from zero (inclusive) to the length of the string (exclusive).
Passing an index that's out of range raises an
\code{IndexOutOfBoundsException}, which is also in the
\code{java.lang} package.

Indexing from position zero (inclusive) to length (exclusive) supports
the conventional \code{for} loop for iterating over items in a sequence,
%
\begin{verbatim}
CharSeqeunce cs = ...;
for (int i = 0; i < cs.length(); ++i) {
    char c = cs.charAt(i);
    ...
}
\end{verbatim}
%
Because lengths are instances of \code{int}, are only allowed to be as
long as the longest positive \code{int} value, $2^{32-1} - 1$, which
is approximately 2 billion.  Any longer sequence of characters needs
to be streamed \eg{with a \code{Reader} or \code{Writer}} or scanned
\eg{with a \code{RandomAccessFile}}.

\subsubsection{Creating Subsequences}

Given a character sequence, a subsequence may be generated using
\code{subSequence(int,int)}, where the two indexes are start position
(inclusive) and end position (exclusive).  As for \code{charAt}, the
indexes must be in range (start greater than or equal to zero and less
than or equal to end, and end less than or equal to the sequence
length). One nice feature of this inclusive-start/exclusive-end
encoding is that the length of the subsequence is the end minus the
start.  

The mutable implementations of \code{CharSequence} approach
subsequencing differently.  The \code{StringBuffer} and
\code{StringBuilder} classes return instances of \code{String}, which
are immutable.  Thus changes to the buffer or builder won't affect any
subsequences generated.  The \code{CharBuffer} abstract class in
\code{java.nio} returns a view into itself rather than an independent
copy.  Thus when the underlying buffer changes, so does the
subsequence.

\subsubsection{Converting Character Sequences to Strings}

The last method in \code{CharSequence} is \code{toString()}, which is
specified to return a string that has the same sequence of characters
as the character sequence.  

\subsubsection{Equality and Hashing}

The \code{CharSequence} interface does not place any constraints on
the behavior of equality or hash codes.  Thus two character sequences
may contain the same sequence of characters while not being equal
and having different hash codes.  We'll discuss equality and hash
codes for particular implementations of \code{CharSequence} in the
next few sections.


\section{\code{String} Class}

Strings are so fundamental to Java that they have special literals and
operators built into the Java language.  Functionally, the class
\code{String}, in the package \code{java.lang}, provides an immutable
implementation of \code{CharSequence}.  Sequence immutability, along
with a careful lazy initialization of the hash code, makes strings
thread safe.

Because \code{String} is declared to be final, there can be no
subclasses defined that might potentially override useful invariants
such as equality, comparability, and serializability.  This is
particularly useful because strings are so widely used as constants
and method inputs and outputs.

\subsection{Constructing a String}

Strings may be constructed from arrays of integer Unicode code points,
arrays of characters, or arrays of bytes.  In all cases, a new array
of characters is allocated to hold the underlying \code{char} values
in the string.  Thus the string becomes immutable and subsequent
changes to the array from which it was constructed will not affect it.

\subsubsection{From Unicode Code Points}

When constructing a string from an array of Unicode code points, the
code points are encoded using UTF-16 and the resulting sequence
converted to a sequence of \code{char} values.  Not all integers are
valid Unicode code points.  This constructor will throw an
\code{IllegalArgumentException} if there are illegal code points in
the sequence.

\subsubsection{From \code{char} Values}

When constructing a string from an array of characters or another
string or character sequence, the characters are just copied into the
new array.  There is no checking to ensure that the sequence of
\code{char} values is a legal UTF-16 sequence.  Thus we never know if
a string is well-formed Unicode.

A string may also be constructed from another string.  In this case, a
deep copy is created with its own fresh underlying array.  this may
seem useless, but consider the behavior of \code{substring()}, as
defined below; in this case, constructing a new copy may actually save
space.  Strings may also be constructed by copying the current
contents of a string builder or string buffer (see the next section
for more about these classes, which implement the builder pattern for
strings).

\subsubsection{From Bytes}

When constructing a string from bytes, a character encoding is used to
convert the bytes into \code{char} values.  Typically character
encodings are specified by name.  Any supported encoding or one of its
aliases may be named; the list of available encodings may be accessed
programatically and listed as shown in \refsec{supported-encodings}.

If a character encoding is not specified, the platform's default is
used, resulting in highly non-portable behavior.

A character encoding is represented as an instance of \code{CharSet},
which is in the \code{java.nio.charset} package.  A \code{CharSet} may
be provided directly to the constructor for \code{String}, or they may
be specified by name.  Instances of \code{CharSet} may be retrieved by
name using the static method \code{CharSet.forName(String)}.

If a byte sequence can't be converted to Unicode code points, its
behavior is determined by the underlying \code{CharSetDecoder}
referenced by the \code{CharSet} instance.  This decoder will
typically replace illegal sequences of bytes with a replacement string
determined by \code{CharSetDecoder.replacement()}, typically a
question mark character.  

If you need more control over the behavior in the face of illegal byte
sequences, you may retrieve the \code{CharSet} by name and then use
its \code{newDecoder()} method to get a \code{CharSetDecoder}.

\subsection{String Literals}

In Java code, strings may be represented as characters surrounded
by double quotes.  For instance,
%
\begin{verbatim}
String name = "Fred";
\end{verbatim}
%
The characters between the quotes can be any characters in the Java
program.  Specifically, they can be Unicode escapes, so we could've
written the above replacing \code{F} and \code{e} with Unicode
escapes, as in
%
\begin{verbatim}
String name = "\u0046r\u0065d";
\end{verbatim}

In practice, string literals essentially create static constants for
the strings.  Because strings are immutable, the value of string
contstants including literals, will be shared.  Thus \code{"abc" ==
  "abc"} will evaluate to true because the two literals will denote
reference identical strings.  This is carried out as if
\code{intern()} had been called on constructed strings, as described
in \refsec{string-intern}.

String literals may contain the same character escape sequences as
character literals (see \refsec{character-literals}).

\subsection{Example Conversions}

We wrote a simple program to illustrate encoding and decoding between
strings and byte arrays.  
%
\codeblock{ByteToString.1}
%
First, the string \stringmention{D\'ej\`a vu} is
assigned to variable
\code{s}.  The string literal uses two Unicode escapes, 
\code{{\bk}u00E9} for \charmention{\'e} and \code{{\bk}u00E0} for 
\charmention{\`a}.  The name of the character encoding to use for
encoding and decoding are read from the command line.  

Then we convert the string \code{s} to an array of bytes
\code{bs} using the character encoding \code{encode}.  Next, we
reconstitute a string using the bytes we just created using the
character encoding \code{decode}.  Either of these methods may raise
an exception if the specified encoding is not supported, so the 
\code{main()} method is declared to throw an
\code{UnsupportedEncodingException}, imported from \code{java.io}.
The rest of the code just prints the relevant characters and bytes.

There is an Ant target \code{byte-to-string} that's configured to take
two arguments consisting of the names of the character encodings.  The
first is used to convert a string to bytes and the second to convert
the bytes back to a string.  For instance, to use UTF-8 to encode and
Latin1 (ISO-8859-1) to decode, the program prints
%
\commandlinefollow{ant -Dencode=UTF-8 -Ddecode=Latin1 byte-to-string}
\begin{verbatim}
char[] from string
  44    e9    6a    e0    20    76    75     a
byte[] from encoding with UTF-8
  68   -61   -87   106   -61   -96    32   118   117    10
char[] from decoding with Latin1
  44    c3    a9    6a    c3    a0    20    76    75     a
\end{verbatim}


\subsection{Contents of a String}

Strings are very heavy objects in Java.  First, they are full-fledged
objects, as opposed to the C-style strings consisting only of a
pointer into an array.  Second, they contain references to an array of
characters, \code{char[]}, holding the actual characters, as well as
an integer start index into that array and an integer length.  They
also store their hash code as an integer.  Thus an empty string will
be 36 bytes in the 32-bit Sun/Oracle JVM and 60 bytes in the 64-bit
JVM.%
%
\footnote{The JVM option \code{-XX:+UseCompressedOops} will reduce
the memory footprint of 64-bit objects to the same size as 32-bit
objects in many cases.}

% String:  8   +8
% offset:  4
% len:     4
% hashcode:4
% arr ref: 4   +4
% array: 8+4   +8

\subsection{String Equality and Comparison}

Two strings are equal if they have the same length and the same
character at each position.  Strings are not equal to objects of any
other runtime class, even other implementations of \code{CharSequence}.

Strings implement \code{Comparable<String>} in a way that is
consistent with equality.  The order they use is lexicographic
sort over the underlying \code{char} values.  This is exactly the
way words are sorted in dictionaries.  The easiest way to define
lexicographic sort is with code, here comparing strings \code{s}
and \code{t}.
%
\begin{verbatim}
for (int i = 0; i < Math.min(s.length(),t.length()); ++i)
    if (s.charAt(i) != t.charAt(i))
        return s.charAt(i) - t.charAt(i);
return s.length() - t.length();
\end{verbatim}

We walk over both strings from the beginning until we find a position
where the characters are different, at which point we return the
difference.%
%
\footnote{Conveniently, \code{char} values are converted to integers
  for arithmetic, allowing negative results for the difference of two
  values.  Also, because string lengths are non-negative, there can't
  be underflow or overflow in the difference.}
%
For instance, \codeString{abc} is less than \codeString{abde}
\codeString{ae}, and \codeString{e}.  If we finish either string, we
return the difference in lengths.  Thus \codeString{a} is less than
\codeString{ab}.  If we finish one of the strings and the strings are
the same length, we return zero, because they are equal.

\subsection{Hash Codes}

The hash code for a string \code{s} is computed as if by
%
\begin{verbatim}
int hashCode = 0;
for (int i = 0; i < s.length(); ++i)
    hashCode = 31 * hashCode + s.charAt(i);
\end{verbatim}
%
This definition is consistent with equals in that two equal strings
have the same character sequence, and hence the same hash code.

Because the hash code is expensive to compute, requiring an
assignment, add and multiply for each character, it is lazily
initialized.  What this means is that when hash code is called, if
there is not a value already, it will be computed and stored. This
operation is thread safe without synchronization because integer
assignment is atomic and the sequence of characters is immutable.

\subsection{Substrings and Subsequences}

The \code{substring(int,int)} and method return subsequences of a
string specified by a start position (inclusive) and an end position
(exclusive).  The \code{subSequence(int,int)} method just delegates to
the substring method.

When a substring is generated from a string, it shares the same array
as the string from which it was generated.  Thus if a large string is
created and a substring generated, the substring will actually hold a
reference to a large array, potentially wasting a great deal of
memory.  Alternatively, if a large string is created and a large
number of substrings are created, this implementation potentially
saves space.

A copy of the character array underlying the string is returned
by \code{toCharArray()}.  

\subsection{Simple Pattern Matching}

Simple text processing may be carried out using methods supplied
by \code{String}.  For instance, \code{endsWith(String)} and
\code{startsWith(String)} return boolean values based on whether
the string has the specified exact suffix or prefix.  These
comparisons are carried out based on the underlying \code{char[]}
array.  There is also a multiple argument \code{regionMatches()}
method that compares a fixed number the characters starting at a given
position to be matched against the characters starting at a different
position in a second string.

There is also a method \code{contains(CharSequence)}, which returns
true if the string contains the characters specified by the character
sequence argument as a substring.  And there is a method
\code{contentEquals(CharSequence)} that compares the character content
of the string with a character sequence.

The \code{indexOf(char,int)} method returns the index of the first
appearance of a character after the specified position, and
\code{lastIndexOf(char,int)} does the same thing in reverse,
returning the last instance of the character before the specified
position.  There are also string-based methods, \code{indexOf(String,int)} and
\code{lastIndexOf(String,int)}.

\subsection{Manipulating Strings}

Several useful string manipulation methods are provided, such as
\code{trim()}, which returns a copy of the string with no whitespace
at the front or end of the string.  The methods
\code{toLowerCase(Locale)} and \code{toUpperCase(Locale)} return a
copy of the string in the specified locale.

\subsection{Unicode Code Points}

The string class also defines methods for manipulating Unicode
code points, which may be coded by either one or two underlying
\code{char} values.  The method \code{codePointAt(int)} returns
the integer code point starting at the specified index.  To find out
the length of a string in unicode code points, there is the method
\code{codePointCount(int,int)} which returns the number of Unicode
code points coded by the specified range of underlying characters.  It
is up to the user to get the boundaries correct.

\subsection{Interning Canonical Representations}\label{section:string-intern}

The JVM keeps an underlying pool of string constants.  A call to
\code{intern()} on a string returns a string in the constant pool.
The method \code{intern()} returns a string that is equal to the
string on which it is called, and is furthermore reference identical
to any other equal string that has also been interned.

For example,  suppose we call
%
\begin{verbatim}
String s = new String("abc");   
String t = new String("abc");   
\end{verbatim}
%
The expression \code{s.equals(t)} will be true, but
\code{s == t} will be false.  The constructor \code{new} always
constructs new objects.  Next, consider calling
%
\begin{verbatim}
String sIn = s.intern();  
String tIn = t.inern();
\end{verbatim}
%
Afterwards, \code{sIn == tIn} will return true, as will
\code{sIn.equals(tIn)}.  The interned strings are equal to their
originals, so that \code{sIn.equals(s)} and \code{tIn.equals(t)} also
return true.


\subsection{Utility Methods}

There are a number of convenience methods in the string class that
reproduce behavior available elsewhere.  

\subsubsection{Regular Expression Utilities}

The string class contains various \code{split()} and
\code{replace}\codeVar{X}\code{()} methods based on regular expressions.
For instance, \code{split(String)} interprets its argument as a
regular expression and returns an array of strings containing the
sequences of text between matches of the specified pattern.
Matching is defined as in the regular expression method
\code{Matcher.find()}.

\subsubsection{String Representations of Primitives}

The string class contains a range of static \code{valueOf()}
methods for converting primitives, objects, and arrays of characters
to strings.  For instance, \code{valueOf(double)} converts a
double-precision floating point value to a string using the same
method as \code{Double.toString(double)}.



\section{\code{StringBuilder} Class}

The \code{StringBuilder} class is essentially a mutable implementation
of the \code{CharSequence} interface.  It contains an underlying array
of \code{char} values, which it resizes as necessary to support a
range of \code{append()} methods.  It implements a standard
builder pattern for strings, where after adding content, \code{toString()}
is used to construct a string based on the buffered values.

A typical use would be to create a string by concatenating the members
of an array, as in
%
\begin{verbatim}
String[] xs = ...;
StringBuilder sb = new StringBuilder();
for (String x : xs)
    sb.append(x);
String s = sb.toString();
\end{verbatim}
%
First a string builder is created, then values are appended to it,
then it is converted to a string.  When a string builder is converted
to a string, a new array is constructed and the buffered contents of
the builder copied into it.

The string builder class lets you append any type of argument, with
the effect being the same as if appending the string resulting from
the matching \code{String.valueOf()} method.  For instance, non-null
objects get converted using their \code{toString()} methods and null
objects are converted to the string \stringmention{null}.  Primitive
numbers converted to their decimal notation, using scientific notation
if necessary, and booleans to either \stringmention{true} or
\stringmention{false}.

The underlying array for buffering characters starts at length 16 by
default, though may be set explicitly in the constructor.  Resizing
adds one to the length then doubles it, leading to roughly log (base
2) resizings in the length of the buffer \eg{16, 34, 70, 142, 286,
  574, \ldots}.  Because string builders are rarely used in locations
that pose a computational bottleneck, this is usually an acceptable
behavior.

In cases where character sequence arguments suffice, this allows us to
bypass the construction of a string altogether.  Thus many of
LingPipe's methods accept character sequence inputs without first
converting to strings.

\subsection{Unicode Support}

The append method \code{appendCodePoint(int)} appends the characters
representing the UTF-16 encoding of the specified Unicode code point.
The builder also supports a \code{codePointAt()}, \code{codePointBefore()},
and \code{codePointCount()} methods with behavior like those for strings.

\subsection{Modifying the Contents}

String builders are mutable, and hence support operations like
\code{setCharAt(int,char)}, which replaces a single character, and
\code{insert(int,String)} and the longer form
\code{replace(int,int,String)}, which splice the characters of a
string into the buffer in place of the specified character slice.
There is also a \code{setLength(int)} method which changes the length
of the charactr sequence, either shrinking or extending the underlying
buffer as necessary.

\subsection{Reversing Character Arrays, Not Strings}

The method \code{reverse()} reverses the order of the \code{char}
values in the buffer.  This is just fine if the characters only encode
Unicode code points at or below \unicode{FFFF}, because there is one
\code{char} per code point.  If there are larger code points, the
reversed array of characters is no longer a legal UTF-16 sequence.


\subsection{Chaining and String Concatenation}

Like many builder implementations, string builders let you chain
arguments.  Thus it's legal to write
%
\begin{verbatim}
String s  = new StringBuilder().append(7).append(" foo").toString();
\end{verbatim}
%
with the reslt that string \code{s} has a value equal to
\code{"7 foo"}.

In fact, this is exactly the behavior underlying Java's heavily
overloaded addition (\code{+}) operator.  When one of the arguments to
addition is a string, the other argument is converted to a string as
if by the appropriate \code{String.valueOf()} method.  Thus an
equivalent way to write the chaining build above is
%
\begin{verbatim}
String s = 7 + " foo";
\end{verbatim}
%
Multiple additions of strings just get unfolded to multiple appends.


\subsection{Equality and Hash Codes}

The \code{StringBuilder} class does not override the definitions of
equality or hash codes in \code{Object}.  Thus two string builders are
equal only if they are reference equal.  In particular, string
builders are never equal to strings.  There is a utility method on
strings, \code{String.contentEquals(CharSequence)} method which
returns true if the char sequence is the same length as the string and
contains the same character as the string at each position.

\subsection{String Buffers}

The class \code{StringBuffer}, which predates
\code{StringBuilder}, is essentially a string builder with
synchronization.  Because it is rarely desirable to write to a
string buffer concurrently, \code{StringBuffer} has all but
disappeared from contemporary Java programs.


\section{\code{CharBuffer} Class}

The \code{CharBuffer} class resides in the \code{java.nio} package
along with corresponding classes for other primitive types, such as
\code{ByteBuffer} and \code{IntBuffer}.  These buffers all hold sequences
of their corresponding primitive types and provide efficient means to
bulk load or bulk dump sequences of the primitive values they hold.

\subsection{Basics of Buffer Positions}

The buffers all extend the \code{Buffer} class, also from
\code{java.nio}.  Buffers may be created backed by an array that holds the appropriate
primitive values, though array backing is not required.

Every buffer has four important integer values that determine how it
behaves, its capacity, position, mark and limit.  Buffers may thus
only have a capacity of up to \code{Integer.MAX\_VALUE} (about 2
billion) primitive values.  

The capacity of a buffer is available through the \code{capacity()}
method.  This is the maximum number of items the buffer can hold.

The position of a buffer is available through the \code{position()}
method and settable with \code{setPosition(int)}.  The position is the
index of the next value to be accessed.  The position must always
be between zero (inclusive) and the buffer's capacity (inclusive).

Relative read and write operations start at the current position and
increment the position by the number of primitive values read or
written.  Underflow or overflow exceptions will be thrown if there are
not enough values to read or write respectively.  There are also
absolute read and write operations which require an explicit index.

The limit for a buffer indicates the first element that should not be
read or written to.  The limit is always between the position (inclusive)
and the capacity (inclusive).

Three general methods are used for resetting these values.  The
\code{clear()} method sets the limit to the capacity and the position
to zero.  The \code{flip()} method sets the limit to the current
position and the position to zero.  The \code{rewind()} method just
sets the position to zero.  

All of the buffers in \code{java.nio} also implement the
\code{compact()} operation, which moves the characters from between
the current position and the limit to the start of the buffer,
resetting the position to be just past the moved characters (limit
minus original position plus one).

Finally, the mark for a buffer indicates the position the buffer will
have after a call to \code{reset()}.  It may be set to the current
position using \code{mark()}.  The mark must always be between the
zero (inclusive) and the position (inclusive).

\subsection{Equality and Comparison}

Equality and comparison work on the remaining characters, which is the
sequence of characters between the current position and the limit.
Two \code{CharBuffer} instances are equal if they have the same number
of (remaining) elements and all these elements are the same.  Thus the
value of \code{hashCode()} only depends on the remaining characters.
Similarly, comparison is done lexicographically using the remaining
characters.

Because hash codes for buffers may change as their elements change,
they should not be put into collections based on their hash code
\ie{\code{HashSet} or \code{HashMap}} or their natural order
\ie{\code{TreeSet} or \code{TreeMap}}.

The \code{length()} and \code{charAt(int)} methods from \code{CharSequence}
are also defined relative to the remaining characters.


\subsection{Creating a \code{CharBuffer}}

A \code{CharBuffer} of a given capacity may be created along with
a new backing array using
\code{CharBuffer.allocate(int)}; a buffer may also be created from
an existing array using \code{CharBuffer.wrap(char[])} or from a slice
of an existing array.  Wrapped buffers are backed by the specified
arrays, so changes to them affect the buffer and vice-versa.

\subsection{Absolute Sets and Gets}

Values may be added or retrieved as if it were an array, using
\code{get(int)}, which returns a
\code{char}, and \code{set(int,char)}, which sets the specified index
to the specified \code{char} value.

\subsection{Relative Sets and Gets}

There are also relative set and get operations, whose behavior is
based on the position of the buffer.  The \code{get()} method returns
the character at the current position and increments the position.
The \code{put(char)} method sets the character at the current position
to the specified value and increments the position.  

In addition to single characters, entire \code{CharSequence} or
\code{char[]} values or slices thereof may be put into the array, with
overflow exceptions raised if not all values fit in the buffer.
Similarly, \code{get(char[])} fills the specified character array
starting from the current position and increments the position,
throwing an exception if there are not enough characters left in the
buffer to fill the specified array.  The portion of the array to fill
may also be specified by slice.

The idiom for bulk copying between arrays is to fill the first array
using relative puts, flip it, then copy to another array using
relative gets.  For instance, to use a \code{CharBuffer} to concatenate
the values in an array, we might use%
%
\footnote{Actually, a \code{StringBuilder} is better for this job
because its size doesn't need to be set in advance like a
\code{CharBuffer}'s.}%
%
\begin{verbatim}
String[] xs = ...;
CharBuffer cb = CharBuffer.allocate(1000);
for (String s : ss)
    cb.put(s);
flip();
String s = cb.toString();
\end{verbatim}
%
After the \code{put()} operations in the loop, the position is
after the last character.  If we were to dump to a string at this
point, we would get nothing.  So we call \code{flip()}, which
sets the position back to zero and the limit to the current
position.  Then when we call \code{toString()}, we get the values
between zero and the limit, namely all the characters we appended.
The call to \code{toString()} does not modify the buffer.







 






\subsection{Thread Safety}

Buffers maintain state and are not synchronized for thread safety.
Read-write synchronization would be sufficient.



\section{\code{Charset} Class}

Conversions between sequences of bytes and sequences of characters are
carried out by three related classes in the \code{java.nio.charset}
package.  A character encoding is represented by the confusingly named
\code{Charset} class.  Encoding characters as bytes is carried out by
an instance of \code{CharsetDecoder} and decoding by an instance of
\code{CharsetEncoder}.  All characters are represented as usual in
Java with sequences of \code{char} values representing UTF-16
encodings of Unicode.

Encoders read from character buffers and write to byte buffers and
decoders work in the opposite direction.  Specifically, they use the
\code{java.nio} classes \code{CharBuffer} and \code{ByteBuffer}.  The
class \code{CharBuffer} implements \code{CharSequence}.

\subsection{Creating a \code{Charset}}

Typically, instances of \code{Charset} and their corresponding
encoders and decoders are specified by name and accessed behind the
scenes.  Examples include constructing strings from bytes, converting
strings to bytes, and constructing \code{char} streams from
\code{byte} streams.

Java's built-in implementations of \code{Charset} may be accessed by
name with the static factory method \code{CharSet.forName(String)},
which returns the character encoding with a specified name.  

It's also possible to implement subclasses of \code{Charset} by
implementing the abstract \code{newEncoder()} and \code{newDecoder()}
methods.  Decoders and encoders need to define behavior in the face of
malformed input and unmappable characters, possibly defining
replacement values. So if you must have Morse code, it's possible to
support it directly.  

\subsection{Decoding and Encoding with a \code{Charset}}

Once a \code{Charset} is obtained, its methods \code{newEncoder()} and
\code{newDecoder()} may be used to get fresh instances of
\code{CharsetEncoder} and \code{CharsetDecoder} as needed. These classes
provide methods for encoding \code{char} buffers as \code{byte}
buffers and decoding \code{byte} buffers to \code{char} buffers.  The
\code{Charset} class also provides convenience methods for decoding
and encoding characters.

The basic encoding method is
\code{encode(CharBuffer,ByteBuffer,boolean)}, which maps the
\code{byte} values in the \code{ByteBuffer} to \code{char} values in
the \code{CharBuffer}.  These buffer classes are in \code{java.nio}.
The third argument is a flag indicating whether or not the bytes are
all the bytes that will ever be coded.  It's also possible to use the
\code{canEncode(char)} or \code{canEncode(CharSequence)} methods to
test for encodability.  

The \code{CharsetEncoder} determines the behavior in the face of
unmappable characters.  The options are determined by the values of
class \code{CodingErrorAction} (also in \code{java.nio.charset}).%
%
\footnote{The error action class is the way type-safe enumerations used to
be encoded before \code{enum}s were added diretly to the language, with
a private constructor and a set of static constant implementations.}%
%
The three actions allowed are to ignore unmappable characters (static
constant \code{IGNORE} in \code{CodingErrorAction}), replace them with
a specified sequence of bytes (\code{REPLACE}), or to report the
error, either by raising an exception or through a return value
(\code{REPORT}).  Whether an exception is raised or an exceptional return
value provided depends on the calling method.  For the replacement option,
the bytes used to replace an unmappable character may be set on the
\code{CharsetEncoder} using the \code{replaceWith(byte[])} method.

The \code{CharsetDecoder} class is similar to the encoder class, only
moving from a \code{CharBuffer} back to a \code{ByteBuffer}.  The way
the decoder handles malformed sequences of bytes is similar to the
encoder's handling of unmappable characters, only allowing a sequence
of \code{char} as a replacement rather than a sequence of \code{byte}
values.

The \code{CharsetEncoder} and \code{CharsetDecoder} classes maintain
buffered state, so are not thread safe.  New instances should be
created for each encoding and decoding job, though they may be reused
after a call to \code{reset()}.



\subsection{Supported Encodings in Java}\label{section:supported-encodings}

Each Java installation supports a range of character encodings, with
one character encoding serving as the default encoding.  Every
compliant Java installation supports all of the UTF encodings of
Unicode.  Other encodings, as specified by \code{Charset}
implementations, may be added at the installation level, or
implemented programatically within a JVM instance.

The supported encodings determine what characters can be used to write
Java programs, as well as which character encoding objects are
available to convert sequences of bytes to sequences of characters.

We provide a class \code{com.lingpipe.book.char.SupportedEncodings} to
display the default encoding and the complete range of other encodings
supported.  The first part of the main pulls out the default encoding
using a static method of \code{java.nio.charset.Charset},
%
\codeblock{SupportedEncodings.1}
%
The code to pull out the full set of encodings along with their
aliases is
%
\codeblock{SupportedEncodings.2}

The result of running the program is
%
\commandlinefollow{ant available-charsets}
\begin{verbatim}
Default Encoding=windows-1252

Big5
     csBig5
...
x-windows-iso2022jp
    windows-iso2022jp
\end{verbatim}
%
The program first writes out the default encoding.  This is
\code{windows-1252} on my Windows install.  It's typically
\code{ISO-8859-1} on Linux installs in the United States.
After that, the program writes all of the encodings, with the official
name followed by a list of aliases that are also recognized.  We
ellided most of the output, because there are dozens of encodings
supported.

