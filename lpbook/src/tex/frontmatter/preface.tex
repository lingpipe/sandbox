\clearpage
\fancyhead{}
\fancyfoot{}
\pagestyle{fancy}
\mychapterstar{Preface}{PREFACE}


\thispagestyle{plain}

\firstchar{L}ingPipe is a library for natural language processing
implemented in Java.  This book explains the tools that are available
in LingPipe and provides examples of how they can be used to build
natural language processing (NLP) applications.

LingPipe's application programming interface (API) is tailored to
abstract over low-level implementation details to enable components
such as tokenizers, feature extractors, or classifiers to be swapped
in a plug-and-play fashion.  LingPipe contains a mixture of heuristic
rule-based components and statistical components, often implementing
the same interfaces, such as chunking or tokenization.

The presentation here will be hands on.  You should be comfortable
reading short and relatively simple Java programs.  Java programming idioms
like loop boundaries being inclusive/exclusive and higher-level design
patterns like visitors will also be presupposed.  More specific
aspects of Java coding relating to text processing, such as streaming
I/O, character decoding, string representations, and regular
expression processing will be discussed in more depth.  We will also
go into some detail on collections, XML/HTML parsing with SAX, and
serialization patterns.

We do not presuppose any knowledge of linguistics beyond a simple
understanding of the terms used in dictionaries such as words,
syllables, pronunciations, and parts of speech such as noun and
preposition.  We will spend considerable time introducing linguistic
concepts, such as word senses or noun phrase chunks, as they relate to
natural language processing modules in LingPipe.

We will do our best to introduce LingPipe's modules and their
application from a hands-on practical API perspective rather than a
theoretical one.  In most cases, such as for logistic regression
classifiers and conditional random field (CRF) taggers and chunkers,
it's possible learn how to effectively fit complex and useful models
without fully understanding the mathematical basis of LingPipe's
estimation and optimization algorithms.  In other cases, such as naive
Bayes classifiers, hierarchical clusterers and hidden Markov models
(HMM), the models are simpler, estimation is a matter of cuonting,
and there is almost no hand-tuning required.

Deeper understanding of LingPipe's algorithms and statistical models
requires familiarity with computational complexity analysis and basic
probability theory including information theory.  We provide suggested
readings in algorithms, statistics, machine learning and linguistics
in \refappendix{reading}.

After introducing LingPipe's modules and their applications at a
programming level, we will provide mathematically precise definitions.
The goal is a complete description of the mathematical models
underlying LingPipe.  To understand these sections will require a
stronger background in algorithms and statistical modeling than
the other sections of the book.

We hope you have as much fun with LingPipe as we've had.
We'd love to hear from you, so drop us a line at {\tt
lingpipe@alias-i.com} with any kind of question or comment.
\\[12pt]
If you'd like to join the LingPipe mailing list, it's at
\begin{itemize}
\item
\hrefurl{http://tech.groups.yahoo.com/group/LingPipe/}
\end{itemize}
%
We also have a blog at
\begin{itemize}
\item
\hrefurl{http://lingpipe-blog.com/}
\end{itemize}



\newlength{\sigWidth}
\settowidth{\sigWidth}{{\small\sc Bob Carpenter}}
\mbox{ }
\hfill
\parbox{\sigWidth}{
Bob Carpenter
\\[2pt]\small
\it New York
\\
\today}
