\chapter{Handlers, Parsers, and Corpora}\label{chapter:corpus}

LingPipe uses a parser-handler pattern for parsing objects out of
files and processing them.  The pattern follows the design of XML's
SAX parser and content handlers, which are built into Java in package
\code{org.xml.sax}.

A parser is created for the format in which the data objects are
represented.  Then a handler for the data objects is created and
attached to the parser.  At this point, the parser may be used to
parse objects from a file or other input specification, and all
objects found in the file will be passed off to the handler for
processing.

Many of LingPipe's modules provide online training through handlers.
For instance, the dynamic language models implement character sequence
handlers.  

LingPipe's batch training modules require an entire corpus for
training.  A corpus represents an entire data set with a built-in
training and test division.  A corpus has methods that take handlers
and deliver to them the training data, the test data, or both.


\section{Handlers and Object Handlers}

\subsection{Handlers}

The marker interface \code{Handler} is included in LingPipe 4 only for
backward compatibility.  The original parser/handler design allowed
for handlers that implemented arbitrary methods, following the design
of the SAX content handler interface.

\subsection{Object Handlers}

As of Lingpipe 4, all built-in parser/handler usage is through the
\code{ObjectHandler<E>} interface, in package
\code{com.aliasi.corpus}, which extends \code{Handler}.  The
\code{ObjectHandler<E>} interface specifies a single method,
\code{handle(E)}, which processes a single data object of type
\code{E}.  It is like a simplified form of the built-in interface for
processing a streaming XML document, \code{ContentHandler}, in package
\code{org.xml.sax}.

\subsection{Demo: Character Counting Handler}

We define a simple text handler in the demo class
\code{CountingTextHandler}.  It's so simple that it doesn't
even need a constructor.
%
\codeblock{CountingTextHandler.1}
%
We declare the class to implement \code{ObjectHandler<CharSequence>}.
This contract is satisfied by our implementation of the
\code{handle(CharSequence)} method.  The method just increments the
counters for number of characters and sequences it's seen.

The \code{main()} method in the same class implements a simple
command-line demo.  It creates a conting text handler, then calls is
handle method with two strings (recall that \code{String} implements
\code{CharSequence}).
%
\codeblock{CountingTextHandler.2}

The Ant target \code{counting-text-handler} calls the main method,
which assumes no command-line arguments.  
%
\commandlinefollow{ant counting-text-handler}
\begin{verbatim}
# seqs=2 # chars=18
\end{verbatim}
%
The output comes from calling the handler's \code{toString()} method,
which is defined to print the number of sequences and characters.  In
most cases, handlers will either hold references to collections they
update or will make summary statistics or other data accumulated from
the calls to the \code{handle()} method.  We'll see more examples when
we discuss parsers and corpora in the following sections.




\section{Parsers}

A parser reads character data from an input source or character
sequence to produce objects of a specified type.  By attaching a
handler to a parser, the handler will receive a stream of
objects produced by the parser.

\subsection{The \code{Parser} Abstract Base Class}

The type hierarchy for a parser is more general than usage in LingPipe
4 demands.  The abstract base class is specified as \code{Parser<H
  extends Handler>}, in package \code{com.aliasi.corpus}.  The generic
specification requires the instantiation of the type parameter
\code{H} to extend the \code{Handler} interface.  

For use in LingPipe 4, all parsers will use object handler insances,
so all parsers will actually extend \code{Parser<ObjectHandler<E>>}
for some arbitrary object type \code{E}.

\subsubsection{Getting and Setting Handlers}

The base parser class implements getters and setters for 
handlers of the appropriate type; \code{getHandler()}
returns the handler, and \code{setHandler(H)} sets the
value of the handler.

\subsubsection{Parsing Methods}

There are a range of parsing methods specified for \code{Parser}.  Two
of them are abstract, \code{parseString(char[],int,int)} and
\code{parse(InputSource)}, which read data from a character array
slice or an input source.  The input source abstraction, borrowed from
XML's SAX parsers, generalizes the specification of a character
sequence through a reader or an input stream or URL plus a character
encoding specification; input sources also conveniently allow a
relative directory to be specified for finding resources such as DTDs
for XML parsing.

There are several helper methods specified on top of these.  The
method \code{parse(CharSequence)} reads directly from a character
sequence.  The \code{parse(File,String)} method reads the characters
to parse from a file using the specified character encoding.%
%
\footnote{The encoding is set in an \code{InputSource}, which a parser
  implementation may choose to ignore.  For instance, an XML parser
  may choose to read the encoding from the header rather than trusting
  the specification.  The helper implementations in LingPipe all
  respect the character encoding declaration.}
%
The method \code{parse(String,String)} reads from a resource specified
as a system identifier, such as a URL, using the specified character
encoding.  There are also two parallel methods, \code{parse(File)} and
\code{parse(String)}, which do not specify their character encodings.


\subsection{Abstract Base Helper Parsers}

There are two helper subclasses of \code{Parser}, both abstract and
both in package \code{com.aliasi.corpus}.  The class
\code{StringParser} requires a concrete subclass to implement the
abstract method \code{parse(char[],int,int)}.  The \code{StringParser}
class implements the \code{parse(InputSource)} method by reading a
character array from the input source using LingPipe's static utility
method \code{Streams.toCharArray(InputSource)}

The second helper subclass is \code{InputSourceParser}, which requires
subclasses to implement \code{parse(InputSource)}.  It implements
\code{parse(char[],int,int)} by converting the character array to an
input source specified through a reader.

\subsection{Line-Based Tagging Parser}

There are two more specialized classes for parsing.  The
\code{LineTaggingParser}, also in \code{com.aliasi.corpus}, parses
output for a tagger from a line-oriented format.  This format is
common due to the simplicity of its parsing and its use in the
Conference on Natural Language Learning (CoNLL).  

\subsection{XML Parser} 

The \code{XMLParser}, in package \code{com.aliasi.corpus}, extends
\code{InputSourceParser} to support parsing of XML-formatted data.
The XML parser requires the method \code{getXMLHandler()} to return an
instance of \code{DefaultHandler} (built into Java in package
\code{org.xml.sax.helpers}).  

The parser works by creating an XML reader using the static method
\code{createXMLReader()} in \code{XMLReaderFactory}, which is in
\code{org.xml.sax.helpers}.  The XML handler returned by the parser
method \code{getXMLHandler()} is then set on the reader as the content
handler, DTD handler, entity resolver, and error handler.  Thus the
XML handler must actually hold a reference to the LingPipe handler or
retain a reference to the parser (for instance, by being an inner
class) and use the \code{getHandler()} method in \code{Parser} to pass
it data.


\subsection{Demo: MedPost Part-of-Speech Tagging Parser}

As an example, we provide a demo class \code{MedPostPosParser}, which
provides a parser for taggings represented in the MedPost format.  The
MedPost corpus is a collection of sentences drawn from biomedical
research titles and abstracts in MEDLINE (see \refsec{corpora-medtag}
for more information and downloading instructions).  This parser will
extract instances of type \code{Tagging<CharSequence>} and send them
to an arbitrary parser specified at run time.

\subsubsection{Corpus Structure}

The MedPost corpus is arranged by line.  For each sentence fragment,
%
\footnote{The sentence fragments were extracted automatically by a
  system that was not 100\% accurate and were left as is for
  annotation.}
%
we have a line indicating its source in MEDLINE followed by a line
with the tokens and part of speech tags.   Here are the first
three entries from file \code{tag\_cl.ioc}.
%
\begin{verbatim}
P01282450A01
Pain_NN management_NN ,_, nutritional_JJ support_NN ,_, ...
P01350716A05
Seven_MC trials_NNS of_II beta-blockers_NNS and_CC 15_MC ...
P01421653A15
CONCLUSIONS_NNS :_: Although_CS more_RR well-designed_VVNJ ...
...
\end{verbatim}
%
We have truncated the part-of-speech tagged lines as indicated by the
ellipses (\code{...}).  The source of the first entry is a MEDLINE
citation with PubMed ID 01282450, with the rest of the annotation,
\code{A01}, indicating it was the first fragment from the abstract.
The first token in the first fragment is \stringmention{Pain}, which
is assigned a singular noun tag, \code{NN}.  The second token is
\stringmention{management}, assigned the same tag.  The third token is
a comma, (\stringmention{,}), assigned a comma (\code{,}) as a
tag. Note that the string \stringmention{beta-blockers} is analyzed as
a single token, and assigned the plural noun tag \code{NNS}, as is
\stringmention{well-designed}, which is assigned a deverbal adjective
category \code{VVNJ}.


\subsubsection{Code Walkthrough}

We define the MedPost parser to extend \code{StringParser}.
%
\codeblock{MedPostPosParser.1}
%
The generic parameter for the parser's handler is specified to be of
type \code{ObjectHandler<Tagging<String>>}.  LingPipe's \code{Tagging}
class, which represents tags applied to a sequence of items, is in
package \code{com.aliasi.tag}; we gloss over its details here as we
are only using it as an example for parsing.

Because we extended \code{StringParser}, we must implement the
\code{parseString()} method, which is done as follows.
%
\codeblock{MedPostPosParser.2}
%
We construct a string out of the character array slice passed in,
switching from the start/end notation of LingPipe and later Java to
the start/length notation of early Java.  We then split it on Unix
newlines, looking at each line in the for-each loop.  If the line
doesn't have an underscore character, there are no part-of-speech
tags, so we ignore it (we also know there are no underscores in the
identifier lines and that there are no comments).  

We send each line in the training data with an underscore in it to the
\code{process()} method.
%
\codeblock{MedPostPosParser.3}
%
In order to construct a tagging, we will collect a list of tokens and
a list of tags.  We split the line on whitespace, and consider the
strings representing token/tag pairs in turn.   For instance, the
first value for \code{pair} we see in processing the fragment above
is \code{Pain\_NN}.  

We break the token/tag pair down into its token and tag components by
splitting on the underscore character (again, keeping in mind that
there are no underscores in the tokens).  We then just add the first
and second elements derived from the split, which are our token and
tag pair.

After we add the tokens and tags from all the sentences, we use them
to construct a tagging.  Then, we use the \code{getHandler()} method,
which is implemented by the superclass \code{Parser}, to get the
handler itself.  The handler then gets called with the tagging
that's just been constructed by calling its \code{handle(Tagging)}
method.  In this way, the handler gets all the taggings produced
by parsing the input data.

Even though we've implemented our parser over character array slices,
through its superclass, we can use it to parse files or input sources.
The \code{main()} method takes a single command-line argument for
the directory containing the tagged data, comprising a set of
files ending in the suffix \code{ioc}.  

The first real work the method does is assign a new tree set of
strings to the final variable \code{tagSet}. 
%
\codeblock{MedPostPosParser.4}
%
It is final because it's used in the anonymous inner class defiend to
create an object to assign to variable \code{handler}.  The anonymous
inner class implements \code{ObjectHandler<Tagging<String>>}, so it
must define a method \code{handle(Tagging<String>)}.  All the handle
method does is add the list of tags found in the tagging to the tag
set.

Next, we create a parser and set its handler to be the
handler we just defined.
%
\codeblock{MedPostPosParser.5}
%
The last thing the main method does before printing out the tag set is
walk over all the files ending in \code{ioc} and parse each of them,
declaring the character encoding to be ASCII (see
\refsec{io-file-extension-filter} for more information on LingPipe's
file extension filter class).

\subsubsection{Running the Demo}

There is an Ant target \code{medpost-parse} that passes
the value of property \code{medpost.dir} to the command
in \code{MedPostPosParser}.  We have downloaded the data
and unpacked it into the directory given in the command,
%
\commandlinefollow{ant -Dmedpost.dir=c:/lpb/data/medtag/medpost medpost-parse}
\begin{verbatim}
#Tags=63    Tags=    ''    (    )    ,    .    :    CC    CC+
... 
VVGJ    VVGN    VVI    VVN    VVNJ    VVZ    ``
\end{verbatim}
%
We've skipped the output for most of the tags, where denoted by
ellipses (\code{...}).


\section{Corpora}

A corpus, in the linguistic sense, is a body of data.  In the context
of LingPipe, a corpus of data may be labeled with some kind of
conceptual or linguistic annotation, or it may consist solely of text
data.

\subsection{The \code{Corpus} Class}

To represent a corpus, LingPipe uses the abstract base class
\code{Corpus}, in package \code{com.aliasi.corpus}.  It is
parameterized generically the same way as a parser, with
\code{Corpus<H extends Handler>}.  As of LingPipe 4, we only really
have need of instances of \code{Corpus<ObjectHandler<E>>}, where
\code{E} is the type of object being represented by the corpus.

The basic work of a corpus class is done by its \code{visitTrain(H)}
and \code{visitTest(H)} methods, where \code{H} is the handler type.
Calling these methods sends all the training or testing events to the
specified handler.  

The method \code{visitCorpus(H)} sends both training and testing
events to the specified handler and \code{visitCorpus(H,H)} sends the
training events to the first handler and the test events to the
second.

In all the LingPipe built ins, these methods will be
\code{visitTrain(ObjectHandler<E>)} and
\code{visitTest(ObjectHandler<E>)} for some object \code{E}.

\subsection{Demo: 20 Newsgroups Corpus}

We will use the 20 newsgroups corpus as an example (see
\refsec{corpora-20-newsgroups}).  The corpus contains around 20,000
newsgroup posts to 20 different newsgroups.

The demo class \code{TwentyNewsgroupsCorpus} implements a corpus based
on this data.  

\subsubsection{Code Walkthrough}

The 20 newsgroups corpus class is defined to extend \code{Corpus}.
%
\codeblock{TwentyNewsgroupsCorpus.1}
%
The handler is an object handler handling objects of type
\code{Classified<CharSequence>}, which represent character sequences
with first-best category assignments from a classification.
In the 20 newsgrops corpus, the categories are the newsgroups from
which the posts originated and the objects being classified,
of type \code{CharSequence}, are the texts of the posts themselves.

The constructor takes the corpus file, which is presumed to be
directory structures that have been tarred and then compressed with
GZIP (see \refsec{io-tar} and \refsec{io-gzip} for more information on
tar and GZIP).  The corpus file is saved for later use.  

The \code{visitTrain()} method sends all the classified character
sequences in the training data to the specified hander.
%
\codeblock{TwentyNewsgroupsCorpus.2}
%
The \code{visitTest()} method is defined similarly.  

The \code{visitFile()} method which is doing the work, is
defined as follows.
%
\codeblock{TwentyNewsgroupsCorpus.3}
%
It takes the string to match against the directories in the tarred
directory data, and the handler.  It starts by creating an input
stream for gzipped tar data.  

Next, it walks through the directories and files in he tarred
data.
%
\codeblock{TwentyNewsgroupsCorpus.4}
%
We loop, getting the next tar entry, breaking out of the loop if the
entry is null, indicating we have processed every entry.  If the entry
is a directory, we skip it.  Otherwise, we get its name, then parse
out the directory structure using the indexes of the directory
structure slash (\code{/}) separators, pulling out the name of the
directory indicating whether we have training or test data.  For
example, a file tar entry with name
\path{20news-bydate-test/alt.atheism/53265} uses the top-level
directory to indicate the training-testing split, here \code{test},
and the subdirectory to indicate the category, here
\code{alt.atheism}.  We are not keeping track of the article number,
though it would make sense to set things up to keep track of it for a
real application.


If the top-level train-test directory doesn't match, we continue.  If
it does match, we pull out the newsgroup name, then read the actual
bytes of the entry using LingPipe's \code{Streams.toByteArray()}
utility method.  We create a string using the ASCII-encoding because
the 20 newsgroups corpus is in ASCII.  We then create a classification
with category corresponding to the name of the newsgroup, and use it
to create the classified cahracter sequence object.  Finally, we give
the classified character sequence to the object handler, which is
defined to handle objects of type \code{Classified<CharSequence>}.

When we finish the loop, we close the tar input stream (which closes
the other streams) and return.

There is a \code{main()} method which is called by the demo,
converting a single command-line argument into a file
\code{tngFileTgz}.  The code starts by defining a final set
of categories, then an anonymous inner class to define a handler.
%
\codeblock{TwentyNewsgroupsCorpus.5}
%
The handle method extracts the best category from the classification
and adds it to the category set.  The category set needed to be final
so that it could be referenced from within the anonymous inner class's
handle method.

Once the handler is defined, we create a corpus from the gzipped
tar file, then send the train and testing events to the handler.
%
\codeblock{TwentyNewsgroupsCorpus.6}
%
The rest of the code just prints out the categories.

\subsubsection{Running the Demo}

The Ant target \code{twenty-newsgroups} invokes the
\code{TwentyNewsgroupsCorpus} command, sending the value of property
\code{tng.tgz} as the command-line argument.
%
\commandlinefollow{ant -Dtng.tgz=c:/lpb/data/20news-bydate.tar.gz twenty-newsgroups}
\begin{verbatim}
Cats= alt.atheism    comp.graphics    comp.os.ms-windows.misc
...
talk.politics.mideast    talk.politics.misc    talk.religion.misc
\end{verbatim}
%
We have left out some in the middle, but the result is indeed the
twenty expected categories, which correspond to the newsgroups.




